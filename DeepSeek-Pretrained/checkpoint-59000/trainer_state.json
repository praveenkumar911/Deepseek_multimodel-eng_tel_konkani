{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9487360905640959,
  "eval_steps": 1000,
  "global_step": 59000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004020068180356339,
      "grad_norm": 2.740760564804077,
      "learning_rate": 1.9999719601419928e-05,
      "loss": 3.9422,
      "step": 250
    },
    {
      "epoch": 0.008040136360712678,
      "grad_norm": 2.3566644191741943,
      "learning_rate": 1.9997972289848505e-05,
      "loss": 3.7255,
      "step": 500
    },
    {
      "epoch": 0.012060204541069016,
      "grad_norm": 2.6930534839630127,
      "learning_rate": 1.9994625160348648e-05,
      "loss": 3.7044,
      "step": 750
    },
    {
      "epoch": 0.016080272721425357,
      "grad_norm": 2.907426595687866,
      "learning_rate": 1.9989678748508744e-05,
      "loss": 3.7041,
      "step": 1000
    },
    {
      "epoch": 0.016080272721425357,
      "eval_loss": 3.657883644104004,
      "eval_runtime": 8.941,
      "eval_samples_per_second": 279.61,
      "eval_steps_per_second": 35.007,
      "step": 1000
    },
    {
      "epoch": 0.020100340901781696,
      "grad_norm": 2.303227663040161,
      "learning_rate": 1.9983133845825114e-05,
      "loss": 3.6325,
      "step": 1250
    },
    {
      "epoch": 0.02412040908213803,
      "grad_norm": 2.61399507522583,
      "learning_rate": 1.9974991499575383e-05,
      "loss": 3.6614,
      "step": 1500
    },
    {
      "epoch": 0.02814047726249437,
      "grad_norm": 1.9452875852584839,
      "learning_rate": 1.9965253012650893e-05,
      "loss": 3.6226,
      "step": 1750
    },
    {
      "epoch": 0.03216054544285071,
      "grad_norm": 2.318101644515991,
      "learning_rate": 1.995391994334821e-05,
      "loss": 3.6343,
      "step": 2000
    },
    {
      "epoch": 0.03216054544285071,
      "eval_loss": 3.6367247104644775,
      "eval_runtime": 9.1393,
      "eval_samples_per_second": 273.543,
      "eval_steps_per_second": 34.248,
      "step": 2000
    },
    {
      "epoch": 0.03618061362320705,
      "grad_norm": 2.6367979049682617,
      "learning_rate": 1.994099410511981e-05,
      "loss": 3.6198,
      "step": 2250
    },
    {
      "epoch": 0.04020068180356339,
      "grad_norm": 2.2468819618225098,
      "learning_rate": 1.9926477566283847e-05,
      "loss": 3.6408,
      "step": 2500
    },
    {
      "epoch": 0.04422074998391973,
      "grad_norm": 3.2829666137695312,
      "learning_rate": 1.9910372649693242e-05,
      "loss": 3.6324,
      "step": 2750
    },
    {
      "epoch": 0.04824081816427606,
      "grad_norm": 2.9278650283813477,
      "learning_rate": 1.9892681932363976e-05,
      "loss": 3.6184,
      "step": 3000
    },
    {
      "epoch": 0.04824081816427606,
      "eval_loss": 3.6263015270233154,
      "eval_runtime": 9.1354,
      "eval_samples_per_second": 273.662,
      "eval_steps_per_second": 34.262,
      "step": 3000
    },
    {
      "epoch": 0.052260886344632405,
      "grad_norm": 2.957247257232666,
      "learning_rate": 1.9873408245062712e-05,
      "loss": 3.5699,
      "step": 3250
    },
    {
      "epoch": 0.05628095452498874,
      "grad_norm": 3.5971264839172363,
      "learning_rate": 1.985255467185386e-05,
      "loss": 3.5927,
      "step": 3500
    },
    {
      "epoch": 0.060301022705345084,
      "grad_norm": 2.7966365814208984,
      "learning_rate": 1.9830124549606077e-05,
      "loss": 3.6368,
      "step": 3750
    },
    {
      "epoch": 0.06432109088570143,
      "grad_norm": 2.480848550796509,
      "learning_rate": 1.9806121467458297e-05,
      "loss": 3.627,
      "step": 4000
    },
    {
      "epoch": 0.06432109088570143,
      "eval_loss": 3.618048906326294,
      "eval_runtime": 9.0375,
      "eval_samples_per_second": 276.625,
      "eval_steps_per_second": 34.634,
      "step": 4000
    },
    {
      "epoch": 0.06834115906605776,
      "grad_norm": 3.0154483318328857,
      "learning_rate": 1.978054926624545e-05,
      "loss": 3.6244,
      "step": 4250
    },
    {
      "epoch": 0.0723612272464141,
      "grad_norm": 2.72544527053833,
      "learning_rate": 1.9753412037883856e-05,
      "loss": 3.6286,
      "step": 4500
    },
    {
      "epoch": 0.07638129542677044,
      "grad_norm": 2.9114766120910645,
      "learning_rate": 1.972471412471646e-05,
      "loss": 3.5753,
      "step": 4750
    },
    {
      "epoch": 0.08040136360712678,
      "grad_norm": 3.150799512863159,
      "learning_rate": 1.9694460118818007e-05,
      "loss": 3.6175,
      "step": 5000
    },
    {
      "epoch": 0.08040136360712678,
      "eval_loss": 3.6129348278045654,
      "eval_runtime": 9.0309,
      "eval_samples_per_second": 276.827,
      "eval_steps_per_second": 34.659,
      "step": 5000
    },
    {
      "epoch": 0.08442143178748311,
      "grad_norm": 2.8559281826019287,
      "learning_rate": 1.966265486126022e-05,
      "loss": 3.6354,
      "step": 5250
    },
    {
      "epoch": 0.08844149996783945,
      "grad_norm": 2.590522050857544,
      "learning_rate": 1.9629439919981487e-05,
      "loss": 3.5917,
      "step": 5500
    },
    {
      "epoch": 0.0924615681481958,
      "grad_norm": 2.41683030128479,
      "learning_rate": 1.9594553826740184e-05,
      "loss": 3.62,
      "step": 5750
    },
    {
      "epoch": 0.09648163632855213,
      "grad_norm": 2.6132619380950928,
      "learning_rate": 1.955813246826886e-05,
      "loss": 3.5963,
      "step": 6000
    },
    {
      "epoch": 0.09648163632855213,
      "eval_loss": 3.607788324356079,
      "eval_runtime": 8.9996,
      "eval_samples_per_second": 277.79,
      "eval_steps_per_second": 34.779,
      "step": 6000
    },
    {
      "epoch": 0.10050170450890847,
      "grad_norm": 2.770230770111084,
      "learning_rate": 1.9520181672503477e-05,
      "loss": 3.5814,
      "step": 6250
    },
    {
      "epoch": 0.10452177268926481,
      "grad_norm": 2.661234140396118,
      "learning_rate": 1.9480707512111743e-05,
      "loss": 3.5982,
      "step": 6500
    },
    {
      "epoch": 0.10854184086962115,
      "grad_norm": 3.069781541824341,
      "learning_rate": 1.94397163035214e-05,
      "loss": 3.5653,
      "step": 6750
    },
    {
      "epoch": 0.11256190904997748,
      "grad_norm": 3.346186637878418,
      "learning_rate": 1.939721460590949e-05,
      "loss": 3.5869,
      "step": 7000
    },
    {
      "epoch": 0.11256190904997748,
      "eval_loss": 3.6046578884124756,
      "eval_runtime": 8.9748,
      "eval_samples_per_second": 278.559,
      "eval_steps_per_second": 34.876,
      "step": 7000
    },
    {
      "epoch": 0.11658197723033382,
      "grad_norm": 2.8265042304992676,
      "learning_rate": 1.935320922015283e-05,
      "loss": 3.6422,
      "step": 7250
    },
    {
      "epoch": 0.12060204541069017,
      "grad_norm": 2.160414695739746,
      "learning_rate": 1.9307707187739727e-05,
      "loss": 3.6369,
      "step": 7500
    },
    {
      "epoch": 0.12462211359104651,
      "grad_norm": 2.807485342025757,
      "learning_rate": 1.9260715789643285e-05,
      "loss": 3.608,
      "step": 7750
    },
    {
      "epoch": 0.12864218177140285,
      "grad_norm": 2.490861177444458,
      "learning_rate": 1.9212242545156304e-05,
      "loss": 3.5948,
      "step": 8000
    },
    {
      "epoch": 0.12864218177140285,
      "eval_loss": 3.6002461910247803,
      "eval_runtime": 8.9665,
      "eval_samples_per_second": 278.816,
      "eval_steps_per_second": 34.908,
      "step": 8000
    },
    {
      "epoch": 0.13266224995175918,
      "grad_norm": 3.2204673290252686,
      "learning_rate": 1.9162295210688123e-05,
      "loss": 3.5867,
      "step": 8250
    },
    {
      "epoch": 0.1366823181321155,
      "grad_norm": 2.902127504348755,
      "learning_rate": 1.911088177852346e-05,
      "loss": 3.6305,
      "step": 8500
    },
    {
      "epoch": 0.14070238631247187,
      "grad_norm": 2.550072431564331,
      "learning_rate": 1.905801047554354e-05,
      "loss": 3.5754,
      "step": 8750
    },
    {
      "epoch": 0.1447224544928282,
      "grad_norm": 2.2969541549682617,
      "learning_rate": 1.9003689761909686e-05,
      "loss": 3.585,
      "step": 9000
    },
    {
      "epoch": 0.1447224544928282,
      "eval_loss": 3.5983006954193115,
      "eval_runtime": 8.9955,
      "eval_samples_per_second": 277.918,
      "eval_steps_per_second": 34.795,
      "step": 9000
    },
    {
      "epoch": 0.14874252267318452,
      "grad_norm": 2.3982081413269043,
      "learning_rate": 1.894792832970955e-05,
      "loss": 3.5824,
      "step": 9250
    },
    {
      "epoch": 0.15276259085354088,
      "grad_norm": 2.2128446102142334,
      "learning_rate": 1.8890966714563103e-05,
      "loss": 3.622,
      "step": 9500
    },
    {
      "epoch": 0.1567826590338972,
      "grad_norm": 2.4277446269989014,
      "learning_rate": 1.883235651425198e-05,
      "loss": 3.6098,
      "step": 9750
    },
    {
      "epoch": 0.16080272721425357,
      "grad_norm": 2.676647901535034,
      "learning_rate": 1.877233301113383e-05,
      "loss": 3.5693,
      "step": 10000
    },
    {
      "epoch": 0.16080272721425357,
      "eval_loss": 3.5954952239990234,
      "eval_runtime": 9.0083,
      "eval_samples_per_second": 277.52,
      "eval_steps_per_second": 34.746,
      "step": 10000
    },
    {
      "epoch": 0.1648227953946099,
      "grad_norm": 2.9022631645202637,
      "learning_rate": 1.8710905809823834e-05,
      "loss": 3.5881,
      "step": 10250
    },
    {
      "epoch": 0.16884286357496622,
      "grad_norm": 2.900693893432617,
      "learning_rate": 1.8648084739548876e-05,
      "loss": 3.6185,
      "step": 10500
    },
    {
      "epoch": 0.17286293175532258,
      "grad_norm": 2.8902273178100586,
      "learning_rate": 1.8583879852574704e-05,
      "loss": 3.6147,
      "step": 10750
    },
    {
      "epoch": 0.1768829999356789,
      "grad_norm": 2.650003433227539,
      "learning_rate": 1.851830142259746e-05,
      "loss": 3.5682,
      "step": 11000
    },
    {
      "epoch": 0.1768829999356789,
      "eval_loss": 3.593082904815674,
      "eval_runtime": 9.032,
      "eval_samples_per_second": 276.795,
      "eval_steps_per_second": 34.655,
      "step": 11000
    },
    {
      "epoch": 0.18090306811603524,
      "grad_norm": 3.2822606563568115,
      "learning_rate": 1.8451359943099713e-05,
      "loss": 3.6281,
      "step": 11250
    },
    {
      "epoch": 0.1849231362963916,
      "grad_norm": 2.9745259284973145,
      "learning_rate": 1.8383341980386548e-05,
      "loss": 3.5832,
      "step": 11500
    },
    {
      "epoch": 0.18894320447674792,
      "grad_norm": 3.229944944381714,
      "learning_rate": 1.8313712096597026e-05,
      "loss": 3.5646,
      "step": 11750
    },
    {
      "epoch": 0.19296327265710425,
      "grad_norm": 2.520305871963501,
      "learning_rate": 1.824275190049233e-05,
      "loss": 3.6295,
      "step": 12000
    },
    {
      "epoch": 0.19296327265710425,
      "eval_loss": 3.5911343097686768,
      "eval_runtime": 8.9758,
      "eval_samples_per_second": 278.527,
      "eval_steps_per_second": 34.872,
      "step": 12000
    },
    {
      "epoch": 0.1969833408374606,
      "grad_norm": 2.441318988800049,
      "learning_rate": 1.8170472746714246e-05,
      "loss": 3.5812,
      "step": 12250
    },
    {
      "epoch": 0.20100340901781694,
      "grad_norm": 2.6756956577301025,
      "learning_rate": 1.8096886200956566e-05,
      "loss": 3.6141,
      "step": 12500
    },
    {
      "epoch": 0.2050234771981733,
      "grad_norm": 2.3945183753967285,
      "learning_rate": 1.802200403811442e-05,
      "loss": 3.6103,
      "step": 12750
    },
    {
      "epoch": 0.20904354537852962,
      "grad_norm": 4.103084564208984,
      "learning_rate": 1.7945838240400118e-05,
      "loss": 3.6213,
      "step": 13000
    },
    {
      "epoch": 0.20904354537852962,
      "eval_loss": 3.588848352432251,
      "eval_runtime": 9.0238,
      "eval_samples_per_second": 277.046,
      "eval_steps_per_second": 34.686,
      "step": 13000
    },
    {
      "epoch": 0.21306361355888595,
      "grad_norm": 2.806208372116089,
      "learning_rate": 1.786840099542582e-05,
      "loss": 3.587,
      "step": 13250
    },
    {
      "epoch": 0.2170836817392423,
      "grad_norm": 2.4880447387695312,
      "learning_rate": 1.7789704694253368e-05,
      "loss": 3.5885,
      "step": 13500
    },
    {
      "epoch": 0.22110374991959864,
      "grad_norm": 2.730768918991089,
      "learning_rate": 1.77097619294115e-05,
      "loss": 3.5913,
      "step": 13750
    },
    {
      "epoch": 0.22512381809995496,
      "grad_norm": 3.058884382247925,
      "learning_rate": 1.7628912638950894e-05,
      "loss": 3.5837,
      "step": 14000
    },
    {
      "epoch": 0.22512381809995496,
      "eval_loss": 3.5865797996520996,
      "eval_runtime": 9.0306,
      "eval_samples_per_second": 276.837,
      "eval_steps_per_second": 34.66,
      "step": 14000
    },
    {
      "epoch": 0.22914388628031132,
      "grad_norm": 2.402825117111206,
      "learning_rate": 1.7546520376712093e-05,
      "loss": 3.5906,
      "step": 14250
    },
    {
      "epoch": 0.23316395446066765,
      "grad_norm": 3.4575440883636475,
      "learning_rate": 1.7462920563757415e-05,
      "loss": 3.5696,
      "step": 14500
    },
    {
      "epoch": 0.23718402264102398,
      "grad_norm": 2.1588327884674072,
      "learning_rate": 1.7378126577247316e-05,
      "loss": 3.5937,
      "step": 14750
    },
    {
      "epoch": 0.24120409082138033,
      "grad_norm": 2.2516651153564453,
      "learning_rate": 1.7292498217389527e-05,
      "loss": 3.5772,
      "step": 15000
    },
    {
      "epoch": 0.24120409082138033,
      "eval_loss": 3.5862245559692383,
      "eval_runtime": 9.0344,
      "eval_samples_per_second": 276.72,
      "eval_steps_per_second": 34.645,
      "step": 15000
    },
    {
      "epoch": 0.24522415900173666,
      "grad_norm": 2.782820463180542,
      "learning_rate": 1.720536141715809e-05,
      "loss": 3.555,
      "step": 15250
    },
    {
      "epoch": 0.24924422718209302,
      "grad_norm": 2.496932029724121,
      "learning_rate": 1.7117071656502098e-05,
      "loss": 3.6187,
      "step": 15500
    },
    {
      "epoch": 0.2532642953624493,
      "grad_norm": 3.0962460041046143,
      "learning_rate": 1.7027643063040424e-05,
      "loss": 3.5629,
      "step": 15750
    },
    {
      "epoch": 0.2572843635428057,
      "grad_norm": 2.8559863567352295,
      "learning_rate": 1.69370899466214e-05,
      "loss": 3.5745,
      "step": 16000
    },
    {
      "epoch": 0.2572843635428057,
      "eval_loss": 3.5843968391418457,
      "eval_runtime": 9.0041,
      "eval_samples_per_second": 277.65,
      "eval_steps_per_second": 34.762,
      "step": 16000
    },
    {
      "epoch": 0.26130443172316203,
      "grad_norm": 2.7421462535858154,
      "learning_rate": 1.6845426797033047e-05,
      "loss": 3.5698,
      "step": 16250
    },
    {
      "epoch": 0.26532449990351836,
      "grad_norm": 2.7443325519561768,
      "learning_rate": 1.6752668281684505e-05,
      "loss": 3.5859,
      "step": 16500
    },
    {
      "epoch": 0.2693445680838747,
      "grad_norm": 2.5979630947113037,
      "learning_rate": 1.6658829243259026e-05,
      "loss": 3.591,
      "step": 16750
    },
    {
      "epoch": 0.273364636264231,
      "grad_norm": 2.526733160018921,
      "learning_rate": 1.656392469733893e-05,
      "loss": 3.5743,
      "step": 17000
    },
    {
      "epoch": 0.273364636264231,
      "eval_loss": 3.5829975605010986,
      "eval_runtime": 9.0071,
      "eval_samples_per_second": 277.559,
      "eval_steps_per_second": 34.75,
      "step": 17000
    },
    {
      "epoch": 0.2773847044445874,
      "grad_norm": 2.6572816371917725,
      "learning_rate": 1.6467969830002934e-05,
      "loss": 3.5905,
      "step": 17250
    },
    {
      "epoch": 0.28140477262494373,
      "grad_norm": 2.5953762531280518,
      "learning_rate": 1.637097999539611e-05,
      "loss": 3.5851,
      "step": 17500
    },
    {
      "epoch": 0.28542484080530006,
      "grad_norm": 2.361260175704956,
      "learning_rate": 1.6272970713273048e-05,
      "loss": 3.5775,
      "step": 17750
    },
    {
      "epoch": 0.2894449089856564,
      "grad_norm": 3.5628650188446045,
      "learning_rate": 1.617395766651445e-05,
      "loss": 3.5317,
      "step": 18000
    },
    {
      "epoch": 0.2894449089856564,
      "eval_loss": 3.5811500549316406,
      "eval_runtime": 9.0061,
      "eval_samples_per_second": 277.588,
      "eval_steps_per_second": 34.754,
      "step": 18000
    },
    {
      "epoch": 0.2934649771660127,
      "grad_norm": 2.674959421157837,
      "learning_rate": 1.6073956698617656e-05,
      "loss": 3.6137,
      "step": 18250
    },
    {
      "epoch": 0.29748504534636905,
      "grad_norm": 3.025768756866455,
      "learning_rate": 1.597298381116145e-05,
      "loss": 3.5713,
      "step": 18500
    },
    {
      "epoch": 0.30150511352672543,
      "grad_norm": 2.256253957748413,
      "learning_rate": 1.5871055161245584e-05,
      "loss": 3.5802,
      "step": 18750
    },
    {
      "epoch": 0.30552518170708176,
      "grad_norm": 2.8354339599609375,
      "learning_rate": 1.5768600380937855e-05,
      "loss": 3.5618,
      "step": 19000
    },
    {
      "epoch": 0.30552518170708176,
      "eval_loss": 3.580317974090576,
      "eval_runtime": 8.9854,
      "eval_samples_per_second": 278.23,
      "eval_steps_per_second": 34.834,
      "step": 19000
    },
    {
      "epoch": 0.3095452498874381,
      "grad_norm": 2.432615041732788,
      "learning_rate": 1.5664812945517104e-05,
      "loss": 3.543,
      "step": 19250
    },
    {
      "epoch": 0.3135653180677944,
      "grad_norm": 2.658782482147217,
      "learning_rate": 1.5560119059363276e-05,
      "loss": 3.5341,
      "step": 19500
    },
    {
      "epoch": 0.31758538624815075,
      "grad_norm": 2.934562921524048,
      "learning_rate": 1.54545354749889e-05,
      "loss": 3.6033,
      "step": 19750
    },
    {
      "epoch": 0.32160545442850713,
      "grad_norm": 2.856876850128174,
      "learning_rate": 1.5348079087270888e-05,
      "loss": 3.5531,
      "step": 20000
    },
    {
      "epoch": 0.32160545442850713,
      "eval_loss": 3.5790317058563232,
      "eval_runtime": 9.0275,
      "eval_samples_per_second": 276.933,
      "eval_steps_per_second": 34.672,
      "step": 20000
    },
    {
      "epoch": 0.32562552260886346,
      "grad_norm": 3.7578043937683105,
      "learning_rate": 1.5240766930747114e-05,
      "loss": 3.5817,
      "step": 20250
    },
    {
      "epoch": 0.3296455907892198,
      "grad_norm": 2.4633781909942627,
      "learning_rate": 1.5132616176890658e-05,
      "loss": 3.5659,
      "step": 20500
    },
    {
      "epoch": 0.3336656589695761,
      "grad_norm": 3.686385154724121,
      "learning_rate": 1.5023644131362098e-05,
      "loss": 3.5875,
      "step": 20750
    },
    {
      "epoch": 0.33768572714993245,
      "grad_norm": 2.4490880966186523,
      "learning_rate": 1.4913868231240391e-05,
      "loss": 3.576,
      "step": 21000
    },
    {
      "epoch": 0.33768572714993245,
      "eval_loss": 3.578078508377075,
      "eval_runtime": 8.9989,
      "eval_samples_per_second": 277.812,
      "eval_steps_per_second": 34.782,
      "step": 21000
    },
    {
      "epoch": 0.3417057953302888,
      "grad_norm": 2.138422727584839,
      "learning_rate": 1.4803749833870082e-05,
      "loss": 3.593,
      "step": 21250
    },
    {
      "epoch": 0.34572586351064516,
      "grad_norm": 2.7058193683624268,
      "learning_rate": 1.4692422086484853e-05,
      "loss": 3.573,
      "step": 21500
    },
    {
      "epoch": 0.3497459316910015,
      "grad_norm": 2.5660359859466553,
      "learning_rate": 1.4580343484749952e-05,
      "loss": 3.5796,
      "step": 21750
    },
    {
      "epoch": 0.3537659998713578,
      "grad_norm": 3.143197774887085,
      "learning_rate": 1.4467531962837557e-05,
      "loss": 3.5957,
      "step": 22000
    },
    {
      "epoch": 0.3537659998713578,
      "eval_loss": 3.576875686645508,
      "eval_runtime": 8.9657,
      "eval_samples_per_second": 278.842,
      "eval_steps_per_second": 34.911,
      "step": 22000
    },
    {
      "epoch": 0.35778606805171415,
      "grad_norm": 2.6102378368377686,
      "learning_rate": 1.4354005572197507e-05,
      "loss": 3.5868,
      "step": 22250
    },
    {
      "epoch": 0.3618061362320705,
      "grad_norm": 3.6770191192626953,
      "learning_rate": 1.4239782478668813e-05,
      "loss": 3.5884,
      "step": 22500
    },
    {
      "epoch": 0.36582620441242686,
      "grad_norm": 2.78731369972229,
      "learning_rate": 1.4124880959572878e-05,
      "loss": 3.5577,
      "step": 22750
    },
    {
      "epoch": 0.3698462725927832,
      "grad_norm": 2.2122342586517334,
      "learning_rate": 1.4009319400788845e-05,
      "loss": 3.5608,
      "step": 23000
    },
    {
      "epoch": 0.3698462725927832,
      "eval_loss": 3.576785087585449,
      "eval_runtime": 9.0395,
      "eval_samples_per_second": 276.564,
      "eval_steps_per_second": 34.626,
      "step": 23000
    },
    {
      "epoch": 0.3738663407731395,
      "grad_norm": 3.424677610397339,
      "learning_rate": 1.3893116293811617e-05,
      "loss": 3.5651,
      "step": 23250
    },
    {
      "epoch": 0.37788640895349584,
      "grad_norm": 2.5153603553771973,
      "learning_rate": 1.3776758753218267e-05,
      "loss": 3.5545,
      "step": 23500
    },
    {
      "epoch": 0.3819064771338522,
      "grad_norm": 2.2358529567718506,
      "learning_rate": 1.365933081166496e-05,
      "loss": 3.584,
      "step": 23750
    },
    {
      "epoch": 0.3859265453142085,
      "grad_norm": 2.819305896759033,
      "learning_rate": 1.3541317325076238e-05,
      "loss": 3.6117,
      "step": 24000
    },
    {
      "epoch": 0.3859265453142085,
      "eval_loss": 3.5746631622314453,
      "eval_runtime": 9.0738,
      "eval_samples_per_second": 275.517,
      "eval_steps_per_second": 34.495,
      "step": 24000
    },
    {
      "epoch": 0.3899466134945649,
      "grad_norm": 2.830609083175659,
      "learning_rate": 1.3422737177290354e-05,
      "loss": 3.5574,
      "step": 24250
    },
    {
      "epoch": 0.3939666816749212,
      "grad_norm": 2.8650174140930176,
      "learning_rate": 1.3303609342819437e-05,
      "loss": 3.5791,
      "step": 24500
    },
    {
      "epoch": 0.39798674985527754,
      "grad_norm": 3.114452362060547,
      "learning_rate": 1.3183952883813267e-05,
      "loss": 3.5927,
      "step": 24750
    },
    {
      "epoch": 0.4020068180356339,
      "grad_norm": 3.24539852142334,
      "learning_rate": 1.3063786947009085e-05,
      "loss": 3.5708,
      "step": 25000
    },
    {
      "epoch": 0.4020068180356339,
      "eval_loss": 3.574355363845825,
      "eval_runtime": 9.0227,
      "eval_samples_per_second": 277.078,
      "eval_steps_per_second": 34.69,
      "step": 25000
    },
    {
      "epoch": 0.4060268862159902,
      "grad_norm": 2.387434959411621,
      "learning_rate": 1.2943130760667835e-05,
      "loss": 3.5794,
      "step": 25250
    },
    {
      "epoch": 0.4100469543963466,
      "grad_norm": 2.460719585418701,
      "learning_rate": 1.2822003631497369e-05,
      "loss": 3.5626,
      "step": 25500
    },
    {
      "epoch": 0.4140670225767029,
      "grad_norm": 2.314358711242676,
      "learning_rate": 1.2700424941563088e-05,
      "loss": 3.5736,
      "step": 25750
    },
    {
      "epoch": 0.41808709075705924,
      "grad_norm": 2.9633615016937256,
      "learning_rate": 1.2578414145186554e-05,
      "loss": 3.5767,
      "step": 26000
    },
    {
      "epoch": 0.41808709075705924,
      "eval_loss": 3.5730061531066895,
      "eval_runtime": 9.0386,
      "eval_samples_per_second": 276.592,
      "eval_steps_per_second": 34.629,
      "step": 26000
    },
    {
      "epoch": 0.42210715893741557,
      "grad_norm": 2.3209388256073,
      "learning_rate": 1.2455990765832517e-05,
      "loss": 3.5797,
      "step": 26250
    },
    {
      "epoch": 0.4261272271177719,
      "grad_norm": 2.8623595237731934,
      "learning_rate": 1.2333174392984866e-05,
      "loss": 3.5666,
      "step": 26500
    },
    {
      "epoch": 0.43014729529812823,
      "grad_norm": 2.3776721954345703,
      "learning_rate": 1.2210478155457379e-05,
      "loss": 3.5841,
      "step": 26750
    },
    {
      "epoch": 0.4341673634784846,
      "grad_norm": 2.937589168548584,
      "learning_rate": 1.2086936187641245e-05,
      "loss": 3.5612,
      "step": 27000
    },
    {
      "epoch": 0.4341673634784846,
      "eval_loss": 3.5726962089538574,
      "eval_runtime": 9.0168,
      "eval_samples_per_second": 277.262,
      "eval_steps_per_second": 34.713,
      "step": 27000
    },
    {
      "epoch": 0.43818743165884094,
      "grad_norm": 3.207719326019287,
      "learning_rate": 1.196306028031901e-05,
      "loss": 3.5483,
      "step": 27250
    },
    {
      "epoch": 0.44220749983919727,
      "grad_norm": 2.041865110397339,
      "learning_rate": 1.1838870255399726e-05,
      "loss": 3.5712,
      "step": 27500
    },
    {
      "epoch": 0.4462275680195536,
      "grad_norm": 2.6734237670898438,
      "learning_rate": 1.1714385985055733e-05,
      "loss": 3.5502,
      "step": 27750
    },
    {
      "epoch": 0.45024763619990993,
      "grad_norm": 2.824864387512207,
      "learning_rate": 1.158962738854283e-05,
      "loss": 3.5805,
      "step": 28000
    },
    {
      "epoch": 0.45024763619990993,
      "eval_loss": 3.571218729019165,
      "eval_runtime": 9.0512,
      "eval_samples_per_second": 276.206,
      "eval_steps_per_second": 34.581,
      "step": 28000
    },
    {
      "epoch": 0.4542677043802663,
      "grad_norm": 2.354170083999634,
      "learning_rate": 1.1464614429012908e-05,
      "loss": 3.6081,
      "step": 28250
    },
    {
      "epoch": 0.45828777256062264,
      "grad_norm": 2.765275001525879,
      "learning_rate": 1.1339367110319563e-05,
      "loss": 3.5618,
      "step": 28500
    },
    {
      "epoch": 0.46230784074097897,
      "grad_norm": 3.103754997253418,
      "learning_rate": 1.1213905473817195e-05,
      "loss": 3.5586,
      "step": 28750
    },
    {
      "epoch": 0.4663279089213353,
      "grad_norm": 2.869568347930908,
      "learning_rate": 1.1088752578960506e-05,
      "loss": 3.5829,
      "step": 29000
    },
    {
      "epoch": 0.4663279089213353,
      "eval_loss": 3.570796012878418,
      "eval_runtime": 9.5147,
      "eval_samples_per_second": 262.751,
      "eval_steps_per_second": 32.896,
      "step": 29000
    },
    {
      "epoch": 0.47034797710169163,
      "grad_norm": 2.401456832885742,
      "learning_rate": 1.0962923221317621e-05,
      "loss": 3.576,
      "step": 29250
    },
    {
      "epoch": 0.47436804528204796,
      "grad_norm": 3.639688730239868,
      "learning_rate": 1.083693978224817e-05,
      "loss": 3.5474,
      "step": 29500
    },
    {
      "epoch": 0.47838811346240434,
      "grad_norm": 2.5774316787719727,
      "learning_rate": 1.0710822420896297e-05,
      "loss": 3.554,
      "step": 29750
    },
    {
      "epoch": 0.48240818164276067,
      "grad_norm": 2.3373024463653564,
      "learning_rate": 1.0584591317835616e-05,
      "loss": 3.5607,
      "step": 30000
    },
    {
      "epoch": 0.48240818164276067,
      "eval_loss": 3.5706048011779785,
      "eval_runtime": 10.3813,
      "eval_samples_per_second": 240.817,
      "eval_steps_per_second": 30.15,
      "step": 30000
    },
    {
      "epoch": 0.486428249823117,
      "grad_norm": 2.730958938598633,
      "learning_rate": 1.045826667184003e-05,
      "loss": 3.5519,
      "step": 30250
    },
    {
      "epoch": 0.4904483180034733,
      "grad_norm": 2.7659647464752197,
      "learning_rate": 1.0331868696651645e-05,
      "loss": 3.5956,
      "step": 30500
    },
    {
      "epoch": 0.49446838618382966,
      "grad_norm": 1.7905104160308838,
      "learning_rate": 1.0205417617746289e-05,
      "loss": 3.5796,
      "step": 30750
    },
    {
      "epoch": 0.49848845436418604,
      "grad_norm": 2.16847825050354,
      "learning_rate": 1.0079439643545418e-05,
      "loss": 3.5223,
      "step": 31000
    },
    {
      "epoch": 0.49848845436418604,
      "eval_loss": 3.56943678855896,
      "eval_runtime": 9.4584,
      "eval_samples_per_second": 264.316,
      "eval_steps_per_second": 33.092,
      "step": 31000
    },
    {
      "epoch": 0.5025085225445424,
      "grad_norm": 2.605130672454834,
      "learning_rate": 9.952943074586997e-06,
      "loss": 3.6005,
      "step": 31250
    },
    {
      "epoch": 0.5065285907248986,
      "grad_norm": 3.0199673175811768,
      "learning_rate": 9.826454035406694e-06,
      "loss": 3.542,
      "step": 31500
    },
    {
      "epoch": 0.510548658905255,
      "grad_norm": 2.2411983013153076,
      "learning_rate": 9.699992766051861e-06,
      "loss": 3.566,
      "step": 31750
    },
    {
      "epoch": 0.5145687270856114,
      "grad_norm": 2.873624801635742,
      "learning_rate": 9.57357950212629e-06,
      "loss": 3.5727,
      "step": 32000
    },
    {
      "epoch": 0.5145687270856114,
      "eval_loss": 3.5681328773498535,
      "eval_runtime": 9.0363,
      "eval_samples_per_second": 276.661,
      "eval_steps_per_second": 34.638,
      "step": 32000
    },
    {
      "epoch": 0.5185887952659677,
      "grad_norm": 2.254957675933838,
      "learning_rate": 9.44723447155222e-06,
      "loss": 3.5744,
      "step": 32250
    },
    {
      "epoch": 0.5226088634463241,
      "grad_norm": 2.468031644821167,
      "learning_rate": 9.320977891333583e-06,
      "loss": 3.557,
      "step": 32500
    },
    {
      "epoch": 0.5266289316266803,
      "grad_norm": 2.769862174987793,
      "learning_rate": 9.194829964320991e-06,
      "loss": 3.5644,
      "step": 32750
    },
    {
      "epoch": 0.5306489998070367,
      "grad_norm": 3.3696656227111816,
      "learning_rate": 9.06931466895287e-06,
      "loss": 3.5649,
      "step": 33000
    },
    {
      "epoch": 0.5306489998070367,
      "eval_loss": 3.5687975883483887,
      "eval_runtime": 9.0511,
      "eval_samples_per_second": 276.211,
      "eval_steps_per_second": 34.582,
      "step": 33000
    },
    {
      "epoch": 0.5346690679873931,
      "grad_norm": 2.119950771331787,
      "learning_rate": 8.943443947978083e-06,
      "loss": 3.5946,
      "step": 33250
    },
    {
      "epoch": 0.5386891361677494,
      "grad_norm": 2.9788572788238525,
      "learning_rate": 8.817742291016015e-06,
      "loss": 3.5815,
      "step": 33500
    },
    {
      "epoch": 0.5427092043481058,
      "grad_norm": 2.686028242111206,
      "learning_rate": 8.692229812121663e-06,
      "loss": 3.5795,
      "step": 33750
    },
    {
      "epoch": 0.546729272528462,
      "grad_norm": 2.4167871475219727,
      "learning_rate": 8.566926595078833e-06,
      "loss": 3.5642,
      "step": 34000
    },
    {
      "epoch": 0.546729272528462,
      "eval_loss": 3.567866086959839,
      "eval_runtime": 9.0613,
      "eval_samples_per_second": 275.899,
      "eval_steps_per_second": 34.543,
      "step": 34000
    },
    {
      "epoch": 0.5507493407088184,
      "grad_norm": 2.8617472648620605,
      "learning_rate": 8.441852690186457e-06,
      "loss": 3.5759,
      "step": 34250
    },
    {
      "epoch": 0.5547694088891748,
      "grad_norm": 2.6052465438842773,
      "learning_rate": 8.317028111050253e-06,
      "loss": 3.5483,
      "step": 34500
    },
    {
      "epoch": 0.5587894770695311,
      "grad_norm": 3.133260488510132,
      "learning_rate": 8.192472831380275e-06,
      "loss": 3.5681,
      "step": 34750
    },
    {
      "epoch": 0.5628095452498875,
      "grad_norm": 2.696821689605713,
      "learning_rate": 8.068206781794824e-06,
      "loss": 3.5435,
      "step": 35000
    },
    {
      "epoch": 0.5628095452498875,
      "eval_loss": 3.5678250789642334,
      "eval_runtime": 9.0782,
      "eval_samples_per_second": 275.384,
      "eval_steps_per_second": 34.478,
      "step": 35000
    },
    {
      "epoch": 0.5668296134302437,
      "grad_norm": 2.3115341663360596,
      "learning_rate": 7.944249846631267e-06,
      "loss": 3.5626,
      "step": 35250
    },
    {
      "epoch": 0.5708496816106001,
      "grad_norm": 3.375744581222534,
      "learning_rate": 7.820621860764268e-06,
      "loss": 3.6107,
      "step": 35500
    },
    {
      "epoch": 0.5748697497909565,
      "grad_norm": 2.9642138481140137,
      "learning_rate": 7.697835002612517e-06,
      "loss": 3.5566,
      "step": 35750
    },
    {
      "epoch": 0.5788898179713128,
      "grad_norm": 2.9692373275756836,
      "learning_rate": 7.574922693201037e-06,
      "loss": 3.5738,
      "step": 36000
    },
    {
      "epoch": 0.5788898179713128,
      "eval_loss": 3.566570997238159,
      "eval_runtime": 9.0234,
      "eval_samples_per_second": 277.056,
      "eval_steps_per_second": 34.687,
      "step": 36000
    },
    {
      "epoch": 0.5829098861516692,
      "grad_norm": 4.6375908851623535,
      "learning_rate": 7.452398430689543e-06,
      "loss": 3.5574,
      "step": 36250
    },
    {
      "epoch": 0.5869299543320254,
      "grad_norm": 2.791217088699341,
      "learning_rate": 7.330281820704673e-06,
      "loss": 3.519,
      "step": 36500
    },
    {
      "epoch": 0.5909500225123818,
      "grad_norm": 3.531167984008789,
      "learning_rate": 7.208592403642855e-06,
      "loss": 3.5644,
      "step": 36750
    },
    {
      "epoch": 0.5949700906927381,
      "grad_norm": 3.119694948196411,
      "learning_rate": 7.0873496515435695e-06,
      "loss": 3.5923,
      "step": 37000
    },
    {
      "epoch": 0.5949700906927381,
      "eval_loss": 3.5664894580841064,
      "eval_runtime": 9.0492,
      "eval_samples_per_second": 276.266,
      "eval_steps_per_second": 34.589,
      "step": 37000
    },
    {
      "epoch": 0.5989901588730945,
      "grad_norm": 2.665083169937134,
      "learning_rate": 6.9665729649735315e-06,
      "loss": 3.5193,
      "step": 37250
    },
    {
      "epoch": 0.6030102270534509,
      "grad_norm": 2.7807929515838623,
      "learning_rate": 6.846281669922348e-06,
      "loss": 3.5603,
      "step": 37500
    },
    {
      "epoch": 0.6070302952338071,
      "grad_norm": 1.9981250762939453,
      "learning_rate": 6.726495014710064e-06,
      "loss": 3.5792,
      "step": 37750
    },
    {
      "epoch": 0.6110503634141635,
      "grad_norm": 2.355947971343994,
      "learning_rate": 6.6077081495529915e-06,
      "loss": 3.5662,
      "step": 38000
    },
    {
      "epoch": 0.6110503634141635,
      "eval_loss": 3.5660018920898438,
      "eval_runtime": 9.052,
      "eval_samples_per_second": 276.181,
      "eval_steps_per_second": 34.578,
      "step": 38000
    },
    {
      "epoch": 0.6150704315945198,
      "grad_norm": 3.4103832244873047,
      "learning_rate": 6.488985983447957e-06,
      "loss": 3.5955,
      "step": 38250
    },
    {
      "epoch": 0.6190904997748762,
      "grad_norm": 3.4860219955444336,
      "learning_rate": 6.370825629579225e-06,
      "loss": 3.5734,
      "step": 38500
    },
    {
      "epoch": 0.6231105679552326,
      "grad_norm": 3.2256550788879395,
      "learning_rate": 6.2532459952859115e-06,
      "loss": 3.5742,
      "step": 38750
    },
    {
      "epoch": 0.6271306361355888,
      "grad_norm": 2.30719256401062,
      "learning_rate": 6.136265894983728e-06,
      "loss": 3.546,
      "step": 39000
    },
    {
      "epoch": 0.6271306361355888,
      "eval_loss": 3.5654780864715576,
      "eval_runtime": 9.0241,
      "eval_samples_per_second": 277.036,
      "eval_steps_per_second": 34.685,
      "step": 39000
    },
    {
      "epoch": 0.6311507043159452,
      "grad_norm": 3.3574161529541016,
      "learning_rate": 6.019904047154418e-06,
      "loss": 3.5373,
      "step": 39250
    },
    {
      "epoch": 0.6351707724963015,
      "grad_norm": 2.326103448867798,
      "learning_rate": 5.904179071350518e-06,
      "loss": 3.5466,
      "step": 39500
    },
    {
      "epoch": 0.6391908406766579,
      "grad_norm": 2.5883898735046387,
      "learning_rate": 5.789109485215978e-06,
      "loss": 3.5717,
      "step": 39750
    },
    {
      "epoch": 0.6432109088570143,
      "grad_norm": 2.724506378173828,
      "learning_rate": 5.675169918146557e-06,
      "loss": 3.5986,
      "step": 40000
    },
    {
      "epoch": 0.6432109088570143,
      "eval_loss": 3.5650835037231445,
      "eval_runtime": 9.0335,
      "eval_samples_per_second": 276.748,
      "eval_steps_per_second": 34.649,
      "step": 40000
    },
    {
      "epoch": 0.6472309770373705,
      "grad_norm": 2.8428213596343994,
      "learning_rate": 5.561463437102305e-06,
      "loss": 3.5613,
      "step": 40250
    },
    {
      "epoch": 0.6512510452177269,
      "grad_norm": 2.4716172218322754,
      "learning_rate": 5.44846718510885e-06,
      "loss": 3.5682,
      "step": 40500
    },
    {
      "epoch": 0.6552711133980832,
      "grad_norm": 3.172212600708008,
      "learning_rate": 5.336199243175477e-06,
      "loss": 3.5576,
      "step": 40750
    },
    {
      "epoch": 0.6592911815784396,
      "grad_norm": 2.7270853519439697,
      "learning_rate": 5.2251221521711126e-06,
      "loss": 3.559,
      "step": 41000
    },
    {
      "epoch": 0.6592911815784396,
      "eval_loss": 3.56476092338562,
      "eval_runtime": 9.1155,
      "eval_samples_per_second": 274.258,
      "eval_steps_per_second": 34.337,
      "step": 41000
    },
    {
      "epoch": 0.663311249758796,
      "grad_norm": 2.892637252807617,
      "learning_rate": 5.114361512486676e-06,
      "loss": 3.5701,
      "step": 41250
    },
    {
      "epoch": 0.6673313179391522,
      "grad_norm": 2.9375133514404297,
      "learning_rate": 5.004382644527303e-06,
      "loss": 3.5746,
      "step": 41500
    },
    {
      "epoch": 0.6713513861195086,
      "grad_norm": 2.6484594345092773,
      "learning_rate": 4.895203146477864e-06,
      "loss": 3.5777,
      "step": 41750
    },
    {
      "epoch": 0.6753714542998649,
      "grad_norm": 3.0478148460388184,
      "learning_rate": 4.786840488612664e-06,
      "loss": 3.5575,
      "step": 42000
    },
    {
      "epoch": 0.6753714542998649,
      "eval_loss": 3.5642664432525635,
      "eval_runtime": 9.0124,
      "eval_samples_per_second": 277.396,
      "eval_steps_per_second": 34.73,
      "step": 42000
    },
    {
      "epoch": 0.6793915224802213,
      "grad_norm": 2.6598401069641113,
      "learning_rate": 4.679312010499949e-06,
      "loss": 3.5827,
      "step": 42250
    },
    {
      "epoch": 0.6834115906605776,
      "grad_norm": 2.763317346572876,
      "learning_rate": 4.572634918227323e-06,
      "loss": 3.6026,
      "step": 42500
    },
    {
      "epoch": 0.6874316588409339,
      "grad_norm": 2.9333770275115967,
      "learning_rate": 4.466826281648541e-06,
      "loss": 3.5487,
      "step": 42750
    },
    {
      "epoch": 0.6914517270212903,
      "grad_norm": 2.9371514320373535,
      "learning_rate": 4.361903031652064e-06,
      "loss": 3.5732,
      "step": 43000
    },
    {
      "epoch": 0.6914517270212903,
      "eval_loss": 3.5638859272003174,
      "eval_runtime": 9.045,
      "eval_samples_per_second": 276.396,
      "eval_steps_per_second": 34.605,
      "step": 43000
    },
    {
      "epoch": 0.6954717952016466,
      "grad_norm": 2.39989972114563,
      "learning_rate": 4.257881957451909e-06,
      "loss": 3.5594,
      "step": 43250
    },
    {
      "epoch": 0.699491863382003,
      "grad_norm": 4.613034248352051,
      "learning_rate": 4.154779703901114e-06,
      "loss": 3.5547,
      "step": 43500
    },
    {
      "epoch": 0.7035119315623592,
      "grad_norm": 2.7251908779144287,
      "learning_rate": 4.052612768828329e-06,
      "loss": 3.5746,
      "step": 43750
    },
    {
      "epoch": 0.7075319997427156,
      "grad_norm": 4.169037342071533,
      "learning_rate": 3.95139750039793e-06,
      "loss": 3.5622,
      "step": 44000
    },
    {
      "epoch": 0.7075319997427156,
      "eval_loss": 3.5637102127075195,
      "eval_runtime": 9.0483,
      "eval_samples_per_second": 276.294,
      "eval_steps_per_second": 34.592,
      "step": 44000
    },
    {
      "epoch": 0.711552067923072,
      "grad_norm": 2.6914937496185303,
      "learning_rate": 3.8511500944940795e-06,
      "loss": 3.5518,
      "step": 44250
    },
    {
      "epoch": 0.7155721361034283,
      "grad_norm": 2.3821136951446533,
      "learning_rate": 3.751886592129155e-06,
      "loss": 3.5633,
      "step": 44500
    },
    {
      "epoch": 0.7195922042837847,
      "grad_norm": 3.326565980911255,
      "learning_rate": 3.6536228768769586e-06,
      "loss": 3.5471,
      "step": 44750
    },
    {
      "epoch": 0.723612272464141,
      "grad_norm": 2.771695852279663,
      "learning_rate": 3.556374672331113e-06,
      "loss": 3.5715,
      "step": 45000
    },
    {
      "epoch": 0.723612272464141,
      "eval_loss": 3.5638601779937744,
      "eval_runtime": 8.9729,
      "eval_samples_per_second": 278.617,
      "eval_steps_per_second": 34.883,
      "step": 45000
    },
    {
      "epoch": 0.7276323406444973,
      "grad_norm": 3.132931709289551,
      "learning_rate": 3.460540333764486e-06,
      "loss": 3.5894,
      "step": 45250
    },
    {
      "epoch": 0.7316524088248537,
      "grad_norm": 2.2863287925720215,
      "learning_rate": 3.365365452617936e-06,
      "loss": 3.5821,
      "step": 45500
    },
    {
      "epoch": 0.73567247700521,
      "grad_norm": 2.924186944961548,
      "learning_rate": 3.2712522074701434e-06,
      "loss": 3.5437,
      "step": 45750
    },
    {
      "epoch": 0.7396925451855664,
      "grad_norm": 2.4263453483581543,
      "learning_rate": 3.17821565778042e-06,
      "loss": 3.5717,
      "step": 46000
    },
    {
      "epoch": 0.7396925451855664,
      "eval_loss": 3.56369686126709,
      "eval_runtime": 8.9805,
      "eval_samples_per_second": 278.381,
      "eval_steps_per_second": 34.853,
      "step": 46000
    },
    {
      "epoch": 0.7437126133659226,
      "grad_norm": 2.5656087398529053,
      "learning_rate": 3.0862706907214724e-06,
      "loss": 3.556,
      "step": 46250
    },
    {
      "epoch": 0.747732681546279,
      "grad_norm": 2.703916072845459,
      "learning_rate": 2.9954320187972465e-06,
      "loss": 3.5546,
      "step": 46500
    },
    {
      "epoch": 0.7517527497266354,
      "grad_norm": 3.075878620147705,
      "learning_rate": 2.9057141774886987e-06,
      "loss": 3.5313,
      "step": 46750
    },
    {
      "epoch": 0.7557728179069917,
      "grad_norm": 2.324758768081665,
      "learning_rate": 2.8171315229279507e-06,
      "loss": 3.5674,
      "step": 47000
    },
    {
      "epoch": 0.7557728179069917,
      "eval_loss": 3.5632717609405518,
      "eval_runtime": 9.0079,
      "eval_samples_per_second": 277.534,
      "eval_steps_per_second": 34.747,
      "step": 47000
    },
    {
      "epoch": 0.7597928860873481,
      "grad_norm": 3.5918805599212646,
      "learning_rate": 2.7300456546428454e-06,
      "loss": 3.5555,
      "step": 47250
    },
    {
      "epoch": 0.7638129542677043,
      "grad_norm": 2.6029560565948486,
      "learning_rate": 2.64377103209126e-06,
      "loss": 3.5761,
      "step": 47500
    },
    {
      "epoch": 0.7678330224480607,
      "grad_norm": 3.012929916381836,
      "learning_rate": 2.5586735109205685e-06,
      "loss": 3.5851,
      "step": 47750
    },
    {
      "epoch": 0.771853090628417,
      "grad_norm": 2.786010980606079,
      "learning_rate": 2.4747667079458703e-06,
      "loss": 3.5608,
      "step": 48000
    },
    {
      "epoch": 0.771853090628417,
      "eval_loss": 3.5629796981811523,
      "eval_runtime": 9.0542,
      "eval_samples_per_second": 276.115,
      "eval_steps_per_second": 34.57,
      "step": 48000
    },
    {
      "epoch": 0.7758731588087734,
      "grad_norm": 3.4658520221710205,
      "learning_rate": 2.392064049450393e-06,
      "loss": 3.5544,
      "step": 48250
    },
    {
      "epoch": 0.7798932269891298,
      "grad_norm": 2.9645121097564697,
      "learning_rate": 2.3105787690371097e-06,
      "loss": 3.5934,
      "step": 48500
    },
    {
      "epoch": 0.783913295169486,
      "grad_norm": 2.613290309906006,
      "learning_rate": 2.2303239055111635e-06,
      "loss": 3.5616,
      "step": 48750
    },
    {
      "epoch": 0.7879333633498424,
      "grad_norm": 3.255549192428589,
      "learning_rate": 2.151312300793473e-06,
      "loss": 3.583,
      "step": 49000
    },
    {
      "epoch": 0.7879333633498424,
      "eval_loss": 3.56282901763916,
      "eval_runtime": 9.0452,
      "eval_samples_per_second": 276.389,
      "eval_steps_per_second": 34.604,
      "step": 49000
    },
    {
      "epoch": 0.7919534315301987,
      "grad_norm": 2.651374578475952,
      "learning_rate": 2.07355659786585e-06,
      "loss": 3.5485,
      "step": 49250
    },
    {
      "epoch": 0.7959734997105551,
      "grad_norm": 2.7394182682037354,
      "learning_rate": 1.997069238747931e-06,
      "loss": 3.5806,
      "step": 49500
    },
    {
      "epoch": 0.7999935678909115,
      "grad_norm": 2.8854479789733887,
      "learning_rate": 1.9218624625062887e-06,
      "loss": 3.5578,
      "step": 49750
    },
    {
      "epoch": 0.8040136360712677,
      "grad_norm": 2.8351633548736572,
      "learning_rate": 1.8479483032959932e-06,
      "loss": 3.582,
      "step": 50000
    },
    {
      "epoch": 0.8040136360712677,
      "eval_loss": 3.5625641345977783,
      "eval_runtime": 9.0059,
      "eval_samples_per_second": 277.595,
      "eval_steps_per_second": 34.755,
      "step": 50000
    },
    {
      "epoch": 0.8080337042516241,
      "grad_norm": 2.685166597366333,
      "learning_rate": 1.7753385884349906e-06,
      "loss": 3.5729,
      "step": 50250
    },
    {
      "epoch": 0.8120537724319804,
      "grad_norm": 2.8900623321533203,
      "learning_rate": 1.7040449365115552e-06,
      "loss": 3.5992,
      "step": 50500
    },
    {
      "epoch": 0.8160738406123368,
      "grad_norm": 2.5729355812072754,
      "learning_rate": 1.6340787555251524e-06,
      "loss": 3.5497,
      "step": 50750
    },
    {
      "epoch": 0.8200939087926932,
      "grad_norm": 3.343945026397705,
      "learning_rate": 1.5654512410609946e-06,
      "loss": 3.5872,
      "step": 51000
    },
    {
      "epoch": 0.8200939087926932,
      "eval_loss": 3.5625622272491455,
      "eval_runtime": 9.0176,
      "eval_samples_per_second": 277.236,
      "eval_steps_per_second": 34.71,
      "step": 51000
    },
    {
      "epoch": 0.8241139769730494,
      "grad_norm": 2.471860885620117,
      "learning_rate": 1.498439783126151e-06,
      "loss": 3.5354,
      "step": 51250
    },
    {
      "epoch": 0.8281340451534058,
      "grad_norm": 2.5738472938537598,
      "learning_rate": 1.4325168670720846e-06,
      "loss": 3.5221,
      "step": 51500
    },
    {
      "epoch": 0.8321541133337621,
      "grad_norm": 2.471362829208374,
      "learning_rate": 1.3679648703124727e-06,
      "loss": 3.5769,
      "step": 51750
    },
    {
      "epoch": 0.8361741815141185,
      "grad_norm": 2.372652292251587,
      "learning_rate": 1.3047941220859606e-06,
      "loss": 3.5913,
      "step": 52000
    },
    {
      "epoch": 0.8361741815141185,
      "eval_loss": 3.5624008178710938,
      "eval_runtime": 9.0486,
      "eval_samples_per_second": 276.285,
      "eval_steps_per_second": 34.591,
      "step": 52000
    },
    {
      "epoch": 0.8401942496944749,
      "grad_norm": 3.877964496612549,
      "learning_rate": 1.243014730611758e-06,
      "loss": 3.5775,
      "step": 52250
    },
    {
      "epoch": 0.8442143178748311,
      "grad_norm": 2.413778781890869,
      "learning_rate": 1.182636581472183e-06,
      "loss": 3.5909,
      "step": 52500
    },
    {
      "epoch": 0.8482343860551875,
      "grad_norm": 2.6066629886627197,
      "learning_rate": 1.1236693360308283e-06,
      "loss": 3.5304,
      "step": 52750
    },
    {
      "epoch": 0.8522544542355438,
      "grad_norm": 3.187861680984497,
      "learning_rate": 1.0661224298866057e-06,
      "loss": 3.5603,
      "step": 53000
    },
    {
      "epoch": 0.8522544542355438,
      "eval_loss": 3.5622901916503906,
      "eval_runtime": 8.9883,
      "eval_samples_per_second": 278.14,
      "eval_steps_per_second": 34.823,
      "step": 53000
    },
    {
      "epoch": 0.8562745224159002,
      "grad_norm": 3.2650744915008545,
      "learning_rate": 1.010005071363912e-06,
      "loss": 3.5238,
      "step": 53250
    },
    {
      "epoch": 0.8602945905962565,
      "grad_norm": 3.1131021976470947,
      "learning_rate": 9.555420781454861e-07,
      "loss": 3.5644,
      "step": 53500
    },
    {
      "epoch": 0.8643146587766128,
      "grad_norm": 2.7051315307617188,
      "learning_rate": 9.023047171816146e-07,
      "loss": 3.5559,
      "step": 53750
    },
    {
      "epoch": 0.8683347269569692,
      "grad_norm": 3.2644546031951904,
      "learning_rate": 8.505231170059213e-07,
      "loss": 3.5639,
      "step": 54000
    },
    {
      "epoch": 0.8683347269569692,
      "eval_loss": 3.5621352195739746,
      "eval_runtime": 9.0689,
      "eval_samples_per_second": 275.668,
      "eval_steps_per_second": 34.514,
      "step": 54000
    },
    {
      "epoch": 0.8723547951373255,
      "grad_norm": 3.3403384685516357,
      "learning_rate": 8.002055634117578e-07,
      "loss": 3.5536,
      "step": 54250
    },
    {
      "epoch": 0.8763748633176819,
      "grad_norm": 2.814357042312622,
      "learning_rate": 7.513601079241761e-07,
      "loss": 3.5604,
      "step": 54500
    },
    {
      "epoch": 0.8803949314980382,
      "grad_norm": 2.8239729404449463,
      "learning_rate": 7.039945665115666e-07,
      "loss": 3.5492,
      "step": 54750
    },
    {
      "epoch": 0.8844149996783945,
      "grad_norm": 2.328401565551758,
      "learning_rate": 6.581165183350002e-07,
      "loss": 3.5486,
      "step": 55000
    },
    {
      "epoch": 0.8844149996783945,
      "eval_loss": 3.5621390342712402,
      "eval_runtime": 9.049,
      "eval_samples_per_second": 276.275,
      "eval_steps_per_second": 34.59,
      "step": 55000
    },
    {
      "epoch": 0.8884350678587509,
      "grad_norm": 2.7643706798553467,
      "learning_rate": 6.137333045354477e-07,
      "loss": 3.5468,
      "step": 55250
    },
    {
      "epoch": 0.8924551360391072,
      "grad_norm": 2.560598611831665,
      "learning_rate": 5.7085202705909e-07,
      "loss": 3.5325,
      "step": 55500
    },
    {
      "epoch": 0.8964752042194636,
      "grad_norm": 2.9636635780334473,
      "learning_rate": 5.294795475209158e-07,
      "loss": 3.5524,
      "step": 55750
    },
    {
      "epoch": 0.9004952723998199,
      "grad_norm": 2.4165849685668945,
      "learning_rate": 4.897788871059972e-07,
      "loss": 3.5338,
      "step": 56000
    },
    {
      "epoch": 0.9004952723998199,
      "eval_loss": 3.5621144771575928,
      "eval_runtime": 8.9943,
      "eval_samples_per_second": 277.954,
      "eval_steps_per_second": 34.8,
      "step": 56000
    },
    {
      "epoch": 0.9045153405801762,
      "grad_norm": 3.3986618518829346,
      "learning_rate": 4.5143752194795277e-07,
      "loss": 3.5633,
      "step": 56250
    },
    {
      "epoch": 0.9085354087605326,
      "grad_norm": 3.0883641242980957,
      "learning_rate": 4.146240627492648e-07,
      "loss": 3.5458,
      "step": 56500
    },
    {
      "epoch": 0.9125554769408889,
      "grad_norm": 2.4670214653015137,
      "learning_rate": 3.7934440018759454e-07,
      "loss": 3.5436,
      "step": 56750
    },
    {
      "epoch": 0.9165755451212453,
      "grad_norm": 2.2724268436431885,
      "learning_rate": 3.4560417951130407e-07,
      "loss": 3.533,
      "step": 57000
    },
    {
      "epoch": 0.9165755451212453,
      "eval_loss": 3.5620274543762207,
      "eval_runtime": 9.0462,
      "eval_samples_per_second": 276.359,
      "eval_steps_per_second": 34.6,
      "step": 57000
    },
    {
      "epoch": 0.9205956133016016,
      "grad_norm": 2.4124534130096436,
      "learning_rate": 3.134087996361268e-07,
      "loss": 3.5175,
      "step": 57250
    },
    {
      "epoch": 0.9246156814819579,
      "grad_norm": 3.6477293968200684,
      "learning_rate": 2.8276341228128055e-07,
      "loss": 3.5806,
      "step": 57500
    },
    {
      "epoch": 0.9286357496623143,
      "grad_norm": 2.919084072113037,
      "learning_rate": 2.5367292114510164e-07,
      "loss": 3.5377,
      "step": 57750
    },
    {
      "epoch": 0.9326558178426706,
      "grad_norm": 3.3957667350769043,
      "learning_rate": 2.2624899233292807e-07,
      "loss": 3.5975,
      "step": 58000
    },
    {
      "epoch": 0.9326558178426706,
      "eval_loss": 3.562049627304077,
      "eval_runtime": 9.2488,
      "eval_samples_per_second": 270.304,
      "eval_steps_per_second": 33.842,
      "step": 58000
    },
    {
      "epoch": 0.936675886023027,
      "grad_norm": 3.1807262897491455,
      "learning_rate": 2.0027574449230424e-07,
      "loss": 3.5799,
      "step": 58250
    },
    {
      "epoch": 0.9406959542033833,
      "grad_norm": 3.5932717323303223,
      "learning_rate": 1.7596508377605737e-07,
      "loss": 3.5678,
      "step": 58500
    },
    {
      "epoch": 0.9447160223837396,
      "grad_norm": 2.659557342529297,
      "learning_rate": 1.5312563649916734e-07,
      "loss": 3.5347,
      "step": 58750
    },
    {
      "epoch": 0.9487360905640959,
      "grad_norm": 2.440417528152466,
      "learning_rate": 1.318618293309959e-07,
      "loss": 3.5601,
      "step": 59000
    },
    {
      "epoch": 0.9487360905640959,
      "eval_loss": 3.5619871616363525,
      "eval_runtime": 9.0223,
      "eval_samples_per_second": 277.092,
      "eval_steps_per_second": 34.692,
      "step": 59000
    }
  ],
  "logging_steps": 250,
  "max_steps": 62188,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.1272541285502157e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
